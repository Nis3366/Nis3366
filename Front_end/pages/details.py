import streamlit as st
from Crawler.get_top_lists import get_top_lists
from Crawler.get_topic_posts import get_topic_posts
from pymongo import MongoClient
import pandas as pd
from datetime  import timedelta
from pyecharts import options as opts
from pyecharts.charts import Pie, Map, Line
import streamlit.components.v1 as components
from Data_management.process_complex_text import get_emotion
st.title("details")

# è¿æ¥åˆ°MongoDB
client = MongoClient('localhost', 27017)
db = client['NIS3366']

st.title("è¯é¢˜è¯¦æƒ…")

# æ·»åŠ åˆ·æ–°æŒ‰é’®
if st.button("ğŸ”„ åˆ·æ–°"):
   st.rerun()  # é‡æ–°è¿è¡Œåº”ç”¨ï¼Œæ¨¡æ‹Ÿåˆ·æ–°æ•ˆæœ

if "details_topics" not in st.session_state:
   # è·å–æ•°æ®åº“ä¸­çš„æ‰€æœ‰é›†åˆåç§°ï¼ˆè¡¨åï¼‰
   collection_names = db.list_collection_names()
   # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰é›†åˆï¼Œæç¤ºç”¨æˆ·
   if not collection_names:
      st.write("æ•°æ®åº“ä¸­æ²¡æœ‰é›†åˆï¼")
   else:
      # åˆ›å»ºä¸€ä¸ªä¸‹æ‹‰èœå•ï¼Œä¾›ç”¨æˆ·é€‰æ‹©è¡¨å
      topic = st.selectbox("è¯·é€‰æ‹©ä¸€ä¸ªè¯é¢˜", collection_names)
      # æ˜¾ç¤ºç”¨æˆ·é€‰æ‹©çš„è¯é¢˜
      st.title(f"è¯é¢˜è¯¦æƒ…: {topic}")
      # è·å–ç”¨æˆ·é€‰æ‹©çš„é›†åˆ
      collection = db[topic]
      # æŸ¥è¯¢æ‰€æœ‰æ•°æ®
      data = list(collection.find())
      # å°†æ•°æ®è½¬æ¢ä¸º DataFrame
      df = pd.DataFrame(data)
else:
   # ä»çƒ­ç‚¹é¡µé¢è·³è½¬è¿‡æ¥çš„è¯·æ±‚
   topic = st.session_state["details_topics"]
   del st.session_state["details_topics"]
   # è·å–æ•°æ®åº“ä¸­çš„æ‰€æœ‰é›†åˆåç§°ï¼ˆè¡¨åï¼‰
   collection_names = db.list_collection_names()
   # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰é›†åˆï¼Œæç¤ºç”¨æˆ·
   if not collection_names:
      st.write("æ•°æ®åº“ä¸­æ²¡æœ‰é›†åˆï¼")
   else:
      # åˆ›å»ºä¸€ä¸ªä¸‹æ‹‰èœå•ï¼Œä¾›ç”¨æˆ·é€‰æ‹©è¡¨å
      st.selectbox("è¯·é€‰æ‹©ä¸€ä¸ªè¯é¢˜", collection_names)
   # è·å–é›†åˆ
   if topic in db.list_collection_names():
         collection = db[topic]
         # æŸ¥è¯¢æ‰€æœ‰æ•°æ®
         data = list(collection.find())
         df = pd.DataFrame(data)
         st.write(f"æˆåŠŸè®¿é—®é›†åˆ: {topic}")
   else:
         st.error(f"é›†åˆ '{topic}' ä¸å­˜åœ¨ï¼")

if 'publish_time' in df.columns:
   # å°† 'publish_time' è½¬æ¢ä¸º datetime ç±»å‹
   df['publish_time'] = pd.to_datetime(df['publish_time'])
   # æå–æ—¥æœŸ
   df['Date'] = df['publish_time'].dt.date
   daily_counts = df['Date'].value_counts().sort_index()
   daily_counts_df = pd.DataFrame({'Date': daily_counts.index, 'Count': daily_counts.values})
   min_date = daily_counts_df['Date'].min()
   max_date = daily_counts_df['Date'].max()
   if (max_date - min_date).days < 6:
      max_date = min_date + timedelta(days=6)
   # ç”Ÿæˆå®Œæ•´çš„æ—¥æœŸèŒƒå›´
   full_date_range = pd.date_range(start=min_date, end=max_date, freq='D')
   full_dates_df = pd.DataFrame({'Date': full_date_range.date})
   merged_df = pd.merge(full_dates_df, daily_counts_df, on='Date', how='left').fillna(0)
   st.write("æ¯æ—¥å‘å¸ƒæ•°é‡ç»Ÿè®¡ï¼š")
   st.write(merged_df)
   # ç»˜åˆ¶æŠ˜çº¿å›¾
   st.line_chart(merged_df.set_index('Date'))
   df['Date'] = df['publish_time'].dt.date  # æå–æ—¥æœŸ
   df['Hour'] = df['publish_time'].dt.hour  # æå–å°æ—¶
   hourly_counts = df.groupby(['Date', 'Hour']).size().reset_index(name='Count')
   hourly_counts['DateTime'] = pd.to_datetime(hourly_counts['Date'].astype(str) + ' ' + hourly_counts['Hour'].astype(str) + ':00')
   st.write("æ¯å°æ—¶å‘å¸ƒæ•°é‡ç»Ÿè®¡ï¼š")
   st.write(hourly_counts[['DateTime', 'Count']])
   st.line_chart(hourly_counts.set_index('DateTime')['Count'])
else:
   st.error("æ•°æ®æ¡†ä¸­ç¼ºå°‘ 'publish_time' åˆ—ï¼")

# å‡è®¾ä½ çš„æ•°æ®æ¡†æ˜¯ dfï¼Œå¹¶ä¸”åŒ…å« 'content_all' åˆ—
# if 'content_all' in df.columns:
#    df['emotion'] = df['content_all'].apply(get_emotion)
#    if 'publish_time' in df.columns:
#       # å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºæ—¥æœŸæ ¼å¼ï¼ˆå¦‚æœéœ€è¦ï¼‰
#       df['publish_time'] = pd.to_datetime(df['publish_time'])
#       df['date'] = df['publish_time'].dt.date  # æŒ‰æ—¥æœŸåˆ†ç»„
#       emotion_over_time = df.groupby(['date', 'emotion']).size().unstack(fill_value=0)
#       emotion_over_time = emotion_over_time.div(emotion_over_time.sum(axis=1), axis=0) * 100  # è®¡ç®—ç™¾åˆ†æ¯”
      
#       # æ£€æŸ¥æ•°æ®æ˜¯å¦æœ‰æ•ˆ
#       if not emotion_over_time.empty:
#          line_chart = Line()
#          for emotion in emotion_over_time.columns:
#             line_chart.add_xaxis(emotion_over_time.index.astype(str).tolist())
#             line_chart.add_yaxis(
#                emotion,
#                emotion_over_time[emotion].tolist(),
#                label_opts=opts.LabelOpts(is_show=False),
#             )
#          line_chart.set_global_opts(
#             title_opts=opts.TitleOpts(title="ä¸åŒæƒ…æ„Ÿéšæ—¶é—´å˜åŒ–çš„å æ¯”"),
#             xaxis_opts=opts.AxisOpts(name="æ—¶é—´"),
#             yaxis_opts=opts.AxisOpts(name="å æ¯” (%)"),
#             legend_opts=opts.LegendOpts(pos_top="10%"),
#             tooltip_opts=opts.TooltipOpts(trigger="axis"),
#          )
#          line_html = line_chart.render_embed()
#          components.html(line_html, height=500)
#       else:
#          st.warning("æ²¡æœ‰å¯ç”¨äºç»˜åˆ¶æŠ˜çº¿å›¾çš„æƒ…æ„Ÿæ•°æ®ã€‚")
#    else:
#       st.warning("æ•°æ®æ¡†ä¸­ç¼ºå°‘æ—¶é—´æˆ³åˆ— 'timestamp'ï¼Œæ— æ³•ç»˜åˆ¶æ—¶é—´å˜åŒ–å›¾ã€‚")
# else:
#    st.warning("æ•°æ®æ¡†ä¸­ç¼ºå°‘ 'content_all' åˆ—ï¼Œæ— æ³•è¿›è¡Œæƒ…æ„Ÿåˆ†æã€‚")

if 'content_all' in df.columns:
    
    df['emotion'] = df['content_all'].apply(get_emotion)
    
    if 'publish_time' in df.columns:
        try:
            # Convert timestamp and extract date
            df['publish_time'] = pd.to_datetime(df['publish_time'])
            df['date'] = df['publish_time'].dt.date
            
            # Ensure we have valid data to work with
            if len(df) == 0 or df['emotion'].isnull().all():
                st.warning("No valid emotion data available.")
            
            # Debug print
            st.write("Preview of data before grouping:", df[['date', 'emotion']].head())
            
            # Group by date and emotion
            try:
                emotion_counts = df.groupby(['date', 'emotion']).size()
                emotion_over_time = emotion_counts.unstack(fill_value=0)
                
                # Calculate percentages
                emotion_over_time = emotion_over_time.div(emotion_over_time.sum(axis=1), axis=0) * 100
                
                if not emotion_over_time.empty:
                    # Create line chart
                    line_chart = Line()
                    dates = emotion_over_time.index.astype(str).tolist()
                    
                    for emotion in emotion_over_time.columns:
                        line_chart.add_xaxis(dates)
                        line_chart.add_yaxis(
                            emotion,
                            emotion_over_time[emotion].tolist(),
                            label_opts=opts.LabelOpts(is_show=False),
                        )
                    
                    line_chart.set_global_opts(
                        title_opts=opts.TitleOpts(title="ä¸åŒæƒ…æ„Ÿéšæ—¶é—´å˜åŒ–çš„å æ¯”"),
                        xaxis_opts=opts.AxisOpts(name="æ—¶é—´"),
                        yaxis_opts=opts.AxisOpts(name="å æ¯” (%)"),
                        legend_opts=opts.LegendOpts(pos_top="10%"),
                        tooltip_opts=opts.TooltipOpts(trigger="axis"),
                    )
                    
                    line_html = line_chart.render_embed()
                    components.html(line_html, height=500)
                else:
                    st.warning("æ²¡æœ‰å¯ç”¨äºç»˜åˆ¶æŠ˜çº¿å›¾çš„æƒ…æ„Ÿæ•°æ®ã€‚")
            
            except Exception as e:
                st.error(f"Error in grouping data: {str(e)}")
                st.write("Debug info - emotion value counts:", df['emotion'].value_counts())
                st.write("Debug info - date value counts:", df['date'].value_counts())
                
        except Exception as e:
            st.error(f"Error processing timestamps: {str(e)}")
            st.write("Sample publish_time values:", df['publish_time'].head().tolist())
    else:
        st.warning("æ•°æ®æ¡†ä¸­ç¼ºå°‘æ—¶é—´æˆ³åˆ— 'publish_time'ï¼Œæ— æ³•ç»˜åˆ¶æ—¶é—´å˜åŒ–å›¾ã€‚")
else:
    st.warning("æ•°æ®æ¡†ä¸­ç¼ºå°‘ 'content_all' åˆ—ï¼Œæ— æ³•è¿›è¡Œæƒ…æ„Ÿåˆ†æã€‚")

# æ ‡å‡†åŒ–çœä»½åç§°
df['location'] = df['location'].fillna("æœªçŸ¥")  # å¤„ç†ç©ºå€¼

# å°†éæ ‡å‡†åç§°è½¬æ¢ä¸ºå®˜æ–¹åç§°
official_names = {
   "åŒ—äº¬": "åŒ—äº¬å¸‚",
   "å¤©æ´¥": "å¤©æ´¥å¸‚",
   "æ²³åŒ—": "æ²³åŒ—çœ",
   "å±±è¥¿": "å±±è¥¿çœ",
   "å†…è’™å¤": "å†…è’™å¤è‡ªæ²»åŒº",
   "è¾½å®": "è¾½å®çœ",
   "å‰æ—": "å‰æ—çœ",
   "é»‘é¾™æ±Ÿ": "é»‘é¾™æ±Ÿçœ",
   "ä¸Šæµ·": "ä¸Šæµ·å¸‚",
   "æ±Ÿè‹": "æ±Ÿè‹çœ",
   "æµ™æ±Ÿ": "æµ™æ±Ÿçœ",
   "å®‰å¾½": "å®‰å¾½çœ",
   "ç¦å»º": "ç¦å»ºçœ",
   "æ±Ÿè¥¿": "æ±Ÿè¥¿çœ",
   "å±±ä¸œ": "å±±ä¸œçœ",
   "æ²³å—": "æ²³å—çœ",
   "æ¹–åŒ—": "æ¹–åŒ—çœ",
   "æ¹–å—": "æ¹–å—çœ",
   "å¹¿ä¸œ": "å¹¿ä¸œçœ",
   "å¹¿è¥¿": "å¹¿è¥¿å£®æ—è‡ªæ²»åŒº",
   "æµ·å—": "æµ·å—çœ",
   "é‡åº†": "é‡åº†å¸‚",
   "å››å·": "å››å·çœ",
   "è´µå·": "è´µå·çœ",
   "äº‘å—": "äº‘å—çœ",
   "è¥¿è—": "è¥¿è—è‡ªæ²»åŒº",
   "é™•è¥¿": "é™•è¥¿çœ",
   "ç”˜è‚ƒ": "ç”˜è‚ƒçœ",
   "é’æµ·": "é’æµ·çœ",
   "å®å¤": "å®å¤å›æ—è‡ªæ²»åŒº",
   "æ–°ç–†": "æ–°ç–†ç»´å¾å°”è‡ªæ²»åŒº",
   "å°æ¹¾": "å°æ¹¾çœ",
   "é¦™æ¸¯": "é¦™æ¸¯ç‰¹åˆ«è¡Œæ”¿åŒº",
   "æ¾³é—¨": "æ¾³é—¨ç‰¹åˆ«è¡Œæ”¿åŒº",
}
df['location'] = df['location'].replace(official_names)

# è¿‡æ»¤æ‰éæ ‡å‡†åç§°ï¼ˆå¦‚â€œæ—¥æœ¬â€ã€â€œç¾å›½â€ã€â€œæœªçŸ¥â€ç­‰ï¼‰
valid_provinces = list(official_names.values())
df = df[df['location'].isin(valid_provinces)]

# ç»Ÿè®¡æ¯ä¸ªçœä»½çš„æ•°é‡
province_counts = df['location'].value_counts().reset_index()
province_counts.columns = ['province', 'count']

# è½¬æ¢ä¸º pyecharts éœ€è¦çš„æ ¼å¼ [(çœä»½, æ•°é‡), ...]
data_for_map = list(zip(province_counts['province'], province_counts['count']))

# æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆæ•°æ®
if not data_for_map:
   st.error("æ²¡æœ‰æœ‰æ•ˆçš„åœ°å›¾æ•°æ®ï¼")
elif province_counts.empty:
   st.error("æ²¡æœ‰æœ‰æ•ˆçš„çœä»½æ•°æ®ï¼")
else:
   # ç»˜åˆ¶åœ°å›¾
   map_chart = (
      Map()
      .add(
            "æ•°æ®å¯†åº¦",
            data_for_map,
            maptype="china",
            is_roam=True,  # å…è®¸åœ°å›¾ç¼©æ”¾å’Œæ‹–åŠ¨
      )
      .set_global_opts(
            title_opts=opts.TitleOpts(title="ä¸­å›½å„çœæ•°æ®å¯†åº¦"),
            visualmap_opts=opts.VisualMapOpts(
               min_=min(province_counts['count']),
               max_=max(province_counts['count']),
            ),
      )
   )
   # ç”Ÿæˆ HTML
   html = map_chart.render_embed()
   # æ¸²æŸ“åœ°å›¾åˆ° Streamlit
   components.html(html, height=600)

   # åˆ›å»ºä¸‹è½½æŒ‰é’®
   st.write("")  # ç©ºè¡Œåˆ†éš”
   col1, col2 = st.columns([0.9, 0.1])  # å°†é¡µé¢åˆ†ä¸ºä¸¤åˆ—ï¼Œåœ°å›¾å  90%ï¼ŒæŒ‰é’®å  10%
   with col1:
      st.write("")  # å ä½ç¬¦
   with col2:
      # å°† province_counts è½¬æ¢ä¸º CSV æ–‡ä»¶
      csv = province_counts.to_csv(index=False).encode('utf-8')
      # æ·»åŠ ä¸‹è½½æŒ‰é’®ï¼Œä½¿ç”¨ç»å…¸å›¾æ ‡ ğŸ“¥
      st.download_button(
            label="ğŸ“¥",  # ä½¿ç”¨å›¾æ ‡ä½œä¸ºæŒ‰é’®
            data=csv,
            file_name="province_counts.csv",
            mime="text/csv",
            key="download_button",
      )