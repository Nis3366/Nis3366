import streamlit as st
from pymongo import MongoClient
import pandas as pd
from datetime  import timedelta
from pyecharts import options as opts
from pyecharts.charts import Pie, Map, Line
import streamlit.components.v1 as components
from Data_management import get_emotion
st.title("details")

# è¿æ¥åˆ°MongoDB
client = MongoClient('localhost', 27017)
db = client['NIS3366']

if "details_topics" not in st.session_state:
   # è·å–æ•°æ®åº“ä¸­çš„æ‰€æœ‰é›†åˆåç§°ï¼ˆè¡¨åï¼‰
   collection_names = db.list_collection_names()
   # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰é›†åˆï¼Œæç¤ºç”¨æˆ·
   if not collection_names:
      st.write("æ•°æ®åº“ä¸­æ²¡æœ‰é›†åˆï¼")
   else:
      # åˆ›å»ºä¸€ä¸ªä¸‹æ‹‰èœå•ï¼Œä¾›ç”¨æˆ·é€‰æ‹©è¡¨å
      topic = st.selectbox("è¯·é€‰æ‹©ä¸€ä¸ªè¯é¢˜", collection_names)
      st.session_state["show"]=topic
      # æ˜¾ç¤ºç”¨æˆ·é€‰æ‹©çš„è¯é¢˜
      st.title(f"{topic}")
      # è·å–ç”¨æˆ·é€‰æ‹©çš„é›†åˆ
      collection = db[topic]
      # æŸ¥è¯¢æ‰€æœ‰æ•°æ®
      data = list(collection.find())
      # å°†æ•°æ®è½¬æ¢ä¸º DataFrame
      df = pd.DataFrame(data)
else:
   # ä»çƒ­ç‚¹é¡µé¢è·³è½¬è¿‡æ¥çš„è¯·æ±‚
   st.session_state["show"] = st.session_state["details_topics"]
   del st.session_state["details_topics"]
   # è·å–æ•°æ®åº“ä¸­çš„æ‰€æœ‰é›†åˆåç§°ï¼ˆè¡¨åï¼‰
   collection_names = db.list_collection_names()
   # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰é›†åˆï¼Œæç¤ºç”¨æˆ·
   if not collection_names:
      st.write("æ•°æ®åº“ä¸­æ²¡æœ‰é›†åˆï¼")
   else:
      # åˆ›å»ºä¸€ä¸ªä¸‹æ‹‰èœå•ï¼Œä¾›ç”¨æˆ·é€‰æ‹©è¡¨å
      st.selectbox("è¯·é€‰æ‹©ä¸€ä¸ªè¯é¢˜", collection_names)
   # è·å–é›†åˆ
   if st.session_state["show"] in db.list_collection_names():
         collection = db[st.session_state["show"]]
         # æŸ¥è¯¢æ‰€æœ‰æ•°æ®
         data = list(collection.find())
         df = pd.DataFrame(data)
         st.title(f"{st.session_state["show"]}")
   else:
         st.error(f"é›†åˆ '{st.session_state["show"]}' ä¸å­˜åœ¨ï¼")

if 'publish_time' in df.columns:
   # å°† 'publish_time' è½¬æ¢ä¸º datetime ç±»å‹
   df['publish_time'] = pd.to_datetime(df['publish_time'])
   # æå–æ—¥æœŸ
   df['Date'] = df['publish_time'].dt.date
   daily_counts = df['Date'].value_counts().sort_index()
   daily_counts_df = pd.DataFrame({'Date': daily_counts.index, 'Count': daily_counts.values})
   min_date = daily_counts_df['Date'].min()
   max_date = daily_counts_df['Date'].max()
   if (max_date - min_date).days < 6:
      max_date = min_date + timedelta(days=6)
   # ç”Ÿæˆå®Œæ•´çš„æ—¥æœŸèŒƒå›´
   full_date_range = pd.date_range(start=min_date, end=max_date, freq='D')
   full_dates_df = pd.DataFrame({'Date': full_date_range.date})
   merged_df = pd.merge(full_dates_df, daily_counts_df, on='Date', how='left').fillna(0)
   st.write("æ¯æ—¥å‘å¸ƒæ•°é‡ç»Ÿè®¡ï¼š")
   st.write(merged_df)
   # ç»˜åˆ¶æŠ˜çº¿å›¾
   st.line_chart(merged_df.set_index('Date'))
   df['Date'] = df['publish_time'].dt.date  # æå–æ—¥æœŸ
   df['Hour'] = df['publish_time'].dt.hour  # æå–å°æ—¶
   hourly_counts = df.groupby(['Date', 'Hour']).size().reset_index(name='Count')
   hourly_counts['DateTime'] = pd.to_datetime(hourly_counts['Date'].astype(str) + ' ' + hourly_counts['Hour'].astype(str) + ':00')
   st.write("æ¯å°æ—¶å‘å¸ƒæ•°é‡ç»Ÿè®¡ï¼š")
   st.write(hourly_counts[['DateTime', 'Count']])
   st.line_chart(hourly_counts.set_index('DateTime')['Count'])
else:
   st.error("æ•°æ®æ¡†ä¸­ç¼ºå°‘ 'publish_time' åˆ—ï¼")

if 'content_all' in df.columns:
    # å¯¹å†…å®¹è¿›è¡Œæƒ…æ„Ÿåˆ†æ
    if 'publish_time' in df.columns:
        try:
            # è½¬æ¢æ—¶é—´æˆ³å¹¶æå–æ—¥æœŸå’Œå°æ—¶
            df['publish_time'] = pd.to_datetime(df['publish_time'])
            df['date'] = df['publish_time'].dt.date
            df['hour'] = df['publish_time'].dt.hour  # æå–å°æ—¶
            
            # ç¡®ä¿æ•°æ®æœ‰æ•ˆ
            if len(df) == 0 or df['emotion'].isnull().all():
                st.warning("æ²¡æœ‰å¯ç”¨çš„æœ‰æ•ˆæƒ…æ„Ÿæ•°æ®ã€‚")
            
            # è°ƒè¯•ä¿¡æ¯
            st.write("é¢„è§ˆæŒ‰å°æ—¶å’ŒæŒ‰å¤©åˆ†ç»„å‰çš„æ•°æ®:", df[['date', 'hour', 'emotion']].head())
            
            # æŒ‰å°æ—¶åˆ†ç»„
            try:
                # æŒ‰å°æ—¶å’Œæƒ…æ„Ÿåˆ†ç»„
                emotion_counts_hour = df.groupby(['hour', 'emotion']).size()
                emotion_over_time_hour = emotion_counts_hour.unstack(fill_value=0)
                
                # è®¡ç®—ç™¾åˆ†æ¯”
                emotion_over_time_hour = emotion_over_time_hour.div(emotion_over_time_hour.sum(axis=1), axis=0) * 100
                
                if not emotion_over_time_hour.empty:
                    # åˆ›å»ºæŒ‰å°æ—¶çš„æŠ˜çº¿å›¾
                    line_chart_hour = Line()
                    hours = emotion_over_time_hour.index.astype(str).tolist()
                    
                    for emotion in emotion_over_time_hour.columns:
                        line_chart_hour.add_xaxis(hours)
                        line_chart_hour.add_yaxis(
                            emotion,
                            emotion_over_time_hour[emotion].tolist(),
                            label_opts=opts.LabelOpts(is_show=False),
                        )
                    
                    line_chart_hour.set_global_opts(
                        title_opts=opts.TitleOpts(title="ä¸åŒæƒ…æ„Ÿéšæ—¶é—´(å°æ—¶)å˜åŒ–çš„å æ¯”"),
                        xaxis_opts=opts.AxisOpts(name="å°æ—¶"),
                        yaxis_opts=opts.AxisOpts(name="å æ¯” (%)"),
                        legend_opts=opts.LegendOpts(pos_top="10%"),
                        tooltip_opts=opts.TooltipOpts(trigger="axis"),
                    )
                    
                    line_html_hour = line_chart_hour.render_embed()
                    st.subheader("æŒ‰å°æ—¶çš„æƒ…æ„Ÿå˜åŒ–")
                    components.html(line_html_hour, height=500)
                else:
                    st.warning("æ²¡æœ‰å¯ç”¨äºç»˜åˆ¶æŒ‰å°æ—¶æŠ˜çº¿å›¾çš„æƒ…æ„Ÿæ•°æ®ã€‚")
            
            except Exception as e:
                st.error(f"æŒ‰å°æ—¶åˆ†ç»„æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                st.write("è°ƒè¯•ä¿¡æ¯ - æƒ…æ„Ÿå€¼è®¡æ•°:", df['emotion'].value_counts())
                st.write("è°ƒè¯•ä¿¡æ¯ - å°æ—¶å€¼è®¡æ•°:", df['hour'].value_counts())
            
            # æŒ‰å¤©åˆ†ç»„
            try:
                # æŒ‰å¤©å’Œæƒ…æ„Ÿåˆ†ç»„
                emotion_counts_date = df.groupby(['date', 'emotion']).size()
                emotion_over_time_date = emotion_counts_date.unstack(fill_value=0)
                
                # è®¡ç®—ç™¾åˆ†æ¯”
                emotion_over_time_date = emotion_over_time_date.div(emotion_over_time_date.sum(axis=1), axis=0) * 100
                
                if not emotion_over_time_date.empty:
                    # åˆ›å»ºæŒ‰å¤©çš„æŠ˜çº¿å›¾
                    line_chart_date = Line()
                    dates = emotion_over_time_date.index.astype(str).tolist()
                    
                    for emotion in emotion_over_time_date.columns:
                        line_chart_date.add_xaxis(dates)
                        line_chart_date.add_yaxis(
                            emotion,
                            emotion_over_time_date[emotion].tolist(),
                            label_opts=opts.LabelOpts(is_show=False),
                        )
                    
                    line_chart_date.set_global_opts(
                        title_opts=opts.TitleOpts(title="ä¸åŒæƒ…æ„Ÿéšæ—¶é—´(å¤©)å˜åŒ–çš„å æ¯”"),
                        xaxis_opts=opts.AxisOpts(name="æ—¥æœŸ"),
                        yaxis_opts=opts.AxisOpts(name="å æ¯” (%)"),
                        legend_opts=opts.LegendOpts(pos_top="10%"),
                        tooltip_opts=opts.TooltipOpts(trigger="axis"),
                    )
                    
                    line_html_date = line_chart_date.render_embed()
                    st.subheader("æŒ‰å¤©çš„æƒ…æ„Ÿå˜åŒ–")
                    components.html(line_html_date, height=500)
                else:
                    st.warning("æ²¡æœ‰å¯ç”¨äºç»˜åˆ¶æŒ‰å¤©æŠ˜çº¿å›¾çš„æƒ…æ„Ÿæ•°æ®ã€‚")
            
            except Exception as e:
                st.error(f"æŒ‰å¤©åˆ†ç»„æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                st.write("è°ƒè¯•ä¿¡æ¯ - æƒ…æ„Ÿå€¼è®¡æ•°:", df['emotion'].value_counts())
                st.write("è°ƒè¯•ä¿¡æ¯ - æ—¥æœŸå€¼è®¡æ•°:", df['date'].value_counts())
                
        except Exception as e:
            st.error(f"å¤„ç†æ—¶é—´æˆ³æ—¶å‡ºé”™: {str(e)}")
            st.write("ç¤ºä¾‹æ—¶é—´æˆ³å€¼:", df['publish_time'].head().tolist())
    else:
        st.warning("æ•°æ®æ¡†ä¸­ç¼ºå°‘æ—¶é—´æˆ³åˆ— 'publish_time'ï¼Œæ— æ³•ç»˜åˆ¶æ—¶é—´å˜åŒ–å›¾ã€‚")
else:
    st.warning("æ•°æ®æ¡†ä¸­ç¼ºå°‘ 'content_all' åˆ—ï¼Œæ— æ³•è¿›è¡Œæƒ…æ„Ÿåˆ†æã€‚")

# æ ‡å‡†åŒ–çœä»½åç§°
df['location'] = df['location'].fillna("æœªçŸ¥")  # å¤„ç†ç©ºå€¼
# å°†éæ ‡å‡†åç§°è½¬æ¢ä¸ºå®˜æ–¹åç§°
official_names = {
   "åŒ—äº¬": "åŒ—äº¬å¸‚",
   "å¤©æ´¥": "å¤©æ´¥å¸‚",
   "æ²³åŒ—": "æ²³åŒ—çœ",
   "å±±è¥¿": "å±±è¥¿çœ",
   "å†…è’™å¤": "å†…è’™å¤è‡ªæ²»åŒº",
   "è¾½å®": "è¾½å®çœ",
   "å‰æ—": "å‰æ—çœ",
   "é»‘é¾™æ±Ÿ": "é»‘é¾™æ±Ÿçœ",
   "ä¸Šæµ·": "ä¸Šæµ·å¸‚",
   "æ±Ÿè‹": "æ±Ÿè‹çœ",
   "æµ™æ±Ÿ": "æµ™æ±Ÿçœ",
   "å®‰å¾½": "å®‰å¾½çœ",
   "ç¦å»º": "ç¦å»ºçœ",
   "æ±Ÿè¥¿": "æ±Ÿè¥¿çœ",
   "å±±ä¸œ": "å±±ä¸œçœ",
   "æ²³å—": "æ²³å—çœ",
   "æ¹–åŒ—": "æ¹–åŒ—çœ",
   "æ¹–å—": "æ¹–å—çœ",
   "å¹¿ä¸œ": "å¹¿ä¸œçœ",
   "å¹¿è¥¿": "å¹¿è¥¿å£®æ—è‡ªæ²»åŒº",
   "æµ·å—": "æµ·å—çœ",
   "é‡åº†": "é‡åº†å¸‚",
   "å››å·": "å››å·çœ",
   "è´µå·": "è´µå·çœ",
   "äº‘å—": "äº‘å—çœ",
   "è¥¿è—": "è¥¿è—è‡ªæ²»åŒº",
   "é™•è¥¿": "é™•è¥¿çœ",
   "ç”˜è‚ƒ": "ç”˜è‚ƒçœ",
   "é’æµ·": "é’æµ·çœ",
   "å®å¤": "å®å¤å›æ—è‡ªæ²»åŒº",
   "æ–°ç–†": "æ–°ç–†ç»´å¾å°”è‡ªæ²»åŒº",
   "å°æ¹¾": "å°æ¹¾çœ",
   "é¦™æ¸¯": "é¦™æ¸¯ç‰¹åˆ«è¡Œæ”¿åŒº",
   "æ¾³é—¨": "æ¾³é—¨ç‰¹åˆ«è¡Œæ”¿åŒº",
}
df['location'] = df['location'].replace(official_names)

# è¿‡æ»¤æ‰éæ ‡å‡†åç§°ï¼ˆå¦‚â€œæ—¥æœ¬â€ã€â€œç¾å›½â€ã€â€œæœªçŸ¥â€ç­‰ï¼‰
valid_provinces = list(official_names.values())
df = df[df['location'].isin(valid_provinces)]

# ç»Ÿè®¡æ¯ä¸ªçœä»½çš„æ•°é‡
province_counts = df['location'].value_counts().reset_index()
province_counts.columns = ['province', 'count']

# è½¬æ¢ä¸º pyecharts éœ€è¦çš„æ ¼å¼ [(çœä»½, æ•°é‡), ...]
data_for_map = list(zip(province_counts['province'], province_counts['count']))

# æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆæ•°æ®
if not data_for_map:
   st.error("æ²¡æœ‰æœ‰æ•ˆçš„åœ°å›¾æ•°æ®ï¼")
elif province_counts.empty:
   st.error("æ²¡æœ‰æœ‰æ•ˆçš„çœä»½æ•°æ®ï¼")
else:
   # ç»˜åˆ¶åœ°å›¾
   map_chart = (
      Map()
      .add(
            "æ•°æ®å¯†åº¦",
            data_for_map,
            maptype="china",
            is_roam=True,  # å…è®¸åœ°å›¾ç¼©æ”¾å’Œæ‹–åŠ¨
      )
      .set_global_opts(
            title_opts=opts.TitleOpts(title="ä¸­å›½å„çœæ•°æ®å¯†åº¦"),
            visualmap_opts=opts.VisualMapOpts(
               min_=min(province_counts['count']),
               max_=max(province_counts['count']),
            ),
      )
   )
   # ç”Ÿæˆ HTML
   html = map_chart.render_embed()
   # æ¸²æŸ“åœ°å›¾åˆ° Streamlit
   components.html(html, height=600)

   # åˆ›å»ºä¸‹è½½æŒ‰é’®
   st.write("")  # ç©ºè¡Œåˆ†éš”
   col1, col2 = st.columns([0.9, 0.1])  # å°†é¡µé¢åˆ†ä¸ºä¸¤åˆ—ï¼Œåœ°å›¾å  90%ï¼ŒæŒ‰é’®å  10%
   with col1:
      st.write("")  # å ä½ç¬¦
   with col2:
      # å°† province_counts è½¬æ¢ä¸º CSV æ–‡ä»¶
      csv = province_counts.to_csv(index=False).encode('utf-8')
      # æ·»åŠ ä¸‹è½½æŒ‰é’®ï¼Œä½¿ç”¨ç»å…¸å›¾æ ‡ ğŸ“¥
      st.download_button(
            label="ğŸ“¥",  # ä½¿ç”¨å›¾æ ‡ä½œä¸ºæŒ‰é’®
            data=csv,
            file_name="province_counts.csv",
            mime="text/csv",
            key="download_button",
      )