import streamlit as st
from Crawler.get_top_lists import get_top_lists
from Crawler.get_topic_posts import get_topic_posts
from pymongo import MongoClient
import pandas as pd
from datetime  import timedelta
from pyecharts import options as opts
from pyecharts.charts import Map
import streamlit.components.v1 as components

st.title("details")

# è¿æ¥åˆ°MongoDB
client = MongoClient('localhost', 27017)
db = client['NIS3366']

st.title("è¯é¢˜è¯¦æƒ…")

if "details_topics" not in st.session_state:
    st.write("ä»Šæ—¥çƒ­ç‚¹æœªåŠ è½½")
else:
   # è·å–ä¼ é€’çš„è¯é¢˜åå­—
   topic = st.session_state["details_topics"]
   st.title(f"è¯é¢˜è¯¦æƒ…: {topic}")
   # è·å–é›†åˆ
   # collection = db["#ä¸œéƒ¨æˆ˜åŒºæµ·æŠ¥æ¯ç˜«#"]
   if topic in db.list_collection_names():
         collection = db[topic]
         # æŸ¥è¯¢æ‰€æœ‰æ•°æ®
         data = list(collection.find())
         df = pd.DataFrame(data)
         st.write(f"æˆåŠŸè®¿é—®é›†åˆ: {topic}")
   else:
         st.error(f"é›†åˆ '{topic}' ä¸å­˜åœ¨ï¼")

   if 'publish_time' in df.columns:
      # å°† 'publish_time' è½¬æ¢ä¸º datetime ç±»å‹
      df['publish_time'] = pd.to_datetime(df['publish_time'])
      
      # æå–æ—¥æœŸ
      df['Date'] = df['publish_time'].dt.date
      
      # ç»Ÿè®¡æ¯æ—¥å‘å¸ƒæ•°é‡
      daily_counts = df['Date'].value_counts().sort_index()
      
      # å°†ç»Ÿè®¡ç»“æœè½¬æ¢ä¸º DataFrame
      daily_counts_df = pd.DataFrame({'Date': daily_counts.index, 'Count': daily_counts.values})
      
      # ç¡®å®šæœ€å°æ—¥æœŸå’Œæœ€å¤§æ—¥æœŸ
      min_date = daily_counts_df['Date'].min()
      max_date = daily_counts_df['Date'].max()
      
      # å¦‚æœæ•°æ®ä¸è¶³ 7 å¤©ï¼Œæ‰©å±•æ—¥æœŸèŒƒå›´
      if (max_date - min_date).days < 6:
         max_date = min_date + timedelta(days=6)
      
      # ç”Ÿæˆå®Œæ•´çš„æ—¥æœŸèŒƒå›´
      full_date_range = pd.date_range(start=min_date, end=max_date, freq='D')
      
      # å°†å®Œæ•´æ—¥æœŸèŒƒå›´è½¬æ¢ä¸º DataFrame
      full_dates_df = pd.DataFrame({'Date': full_date_range.date})
      
      # åˆå¹¶å®Œæ•´æ—¥æœŸèŒƒå›´å’Œç»Ÿè®¡ç»“æœï¼Œå¡«å……ç¼ºå¤±æ—¥æœŸä¸º 0
      merged_df = pd.merge(full_dates_df, daily_counts_df, on='Date', how='left').fillna(0)
      
      # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
      st.write("æ¯æ—¥å‘å¸ƒæ•°é‡ç»Ÿè®¡ï¼š")
      st.write(merged_df)
      
      # ç»˜åˆ¶æŠ˜çº¿å›¾
      st.line_chart(merged_df.set_index('Date'))
      
      # æå–æ—¥æœŸå’Œå°æ—¶
      df['Date'] = df['publish_time'].dt.date  # æå–æ—¥æœŸ
      df['Hour'] = df['publish_time'].dt.hour  # æå–å°æ—¶
      
      # æŒ‰æ—¥æœŸå’Œå°æ—¶åˆ†ç»„ç»Ÿè®¡
      hourly_counts = df.groupby(['Date', 'Hour']).size().reset_index(name='Count')
      
      # å°† Date å’Œ Hour ç»„åˆæˆä¸€ä¸ª datetime åˆ—
      hourly_counts['DateTime'] = pd.to_datetime(hourly_counts['Date'].astype(str) + ' ' + hourly_counts['Hour'].astype(str) + ':00')
      
      # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
      st.write("æ¯å°æ—¶å‘å¸ƒæ•°é‡ç»Ÿè®¡ï¼š")
      st.write(hourly_counts[['DateTime', 'Count']])
      
      # ç»˜åˆ¶æŠ˜çº¿å›¾
      st.line_chart(hourly_counts.set_index('DateTime')['Count'])
   else:
      st.error("æ•°æ®æ¡†ä¸­ç¼ºå°‘ 'publish_time' åˆ—ï¼")


   # æ ‡å‡†åŒ–çœä»½åç§°
   df['location'] = df['location'].fillna("æœªçŸ¥")  # å¤„ç†ç©ºå€¼

   # å°†éæ ‡å‡†åç§°è½¬æ¢ä¸ºå®˜æ–¹åç§°
   official_names = {
      "åŒ—äº¬": "åŒ—äº¬å¸‚",
      "å¤©æ´¥": "å¤©æ´¥å¸‚",
      "æ²³åŒ—": "æ²³åŒ—çœ",
      "å±±è¥¿": "å±±è¥¿çœ",
      "å†…è’™å¤": "å†…è’™å¤è‡ªæ²»åŒº",
      "è¾½å®": "è¾½å®çœ",
      "å‰æ—": "å‰æ—çœ",
      "é»‘é¾™æ±Ÿ": "é»‘é¾™æ±Ÿçœ",
      "ä¸Šæµ·": "ä¸Šæµ·å¸‚",
      "æ±Ÿè‹": "æ±Ÿè‹çœ",
      "æµ™æ±Ÿ": "æµ™æ±Ÿçœ",
      "å®‰å¾½": "å®‰å¾½çœ",
      "ç¦å»º": "ç¦å»ºçœ",
      "æ±Ÿè¥¿": "æ±Ÿè¥¿çœ",
      "å±±ä¸œ": "å±±ä¸œçœ",
      "æ²³å—": "æ²³å—çœ",
      "æ¹–åŒ—": "æ¹–åŒ—çœ",
      "æ¹–å—": "æ¹–å—çœ",
      "å¹¿ä¸œ": "å¹¿ä¸œçœ",
      "å¹¿è¥¿": "å¹¿è¥¿å£®æ—è‡ªæ²»åŒº",
      "æµ·å—": "æµ·å—çœ",
      "é‡åº†": "é‡åº†å¸‚",
      "å››å·": "å››å·çœ",
      "è´µå·": "è´µå·çœ",
      "äº‘å—": "äº‘å—çœ",
      "è¥¿è—": "è¥¿è—è‡ªæ²»åŒº",
      "é™•è¥¿": "é™•è¥¿çœ",
      "ç”˜è‚ƒ": "ç”˜è‚ƒçœ",
      "é’æµ·": "é’æµ·çœ",
      "å®å¤": "å®å¤å›æ—è‡ªæ²»åŒº",
      "æ–°ç–†": "æ–°ç–†ç»´å¾å°”è‡ªæ²»åŒº",
      "å°æ¹¾": "å°æ¹¾çœ",
      "é¦™æ¸¯": "é¦™æ¸¯ç‰¹åˆ«è¡Œæ”¿åŒº",
      "æ¾³é—¨": "æ¾³é—¨ç‰¹åˆ«è¡Œæ”¿åŒº",
   }
   df['location'] = df['location'].replace(official_names)

   # è¿‡æ»¤æ‰éæ ‡å‡†åç§°ï¼ˆå¦‚â€œæ—¥æœ¬â€ã€â€œç¾å›½â€ã€â€œæœªçŸ¥â€ç­‰ï¼‰
   valid_provinces = list(official_names.values())
   df = df[df['location'].isin(valid_provinces)]

   # ç»Ÿè®¡æ¯ä¸ªçœä»½çš„æ•°é‡
   province_counts = df['location'].value_counts().reset_index()
   province_counts.columns = ['province', 'count']

   # è½¬æ¢ä¸º pyecharts éœ€è¦çš„æ ¼å¼ [(çœä»½, æ•°é‡), ...]
   data_for_map = list(zip(province_counts['province'], province_counts['count']))

   # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆæ•°æ®
   if not data_for_map:
      st.error("æ²¡æœ‰æœ‰æ•ˆçš„åœ°å›¾æ•°æ®ï¼")
   elif province_counts.empty:
      st.error("æ²¡æœ‰æœ‰æ•ˆçš„çœä»½æ•°æ®ï¼")
   else:
      # ç»˜åˆ¶åœ°å›¾
      map_chart = (
         Map()
         .add(
               "æ•°æ®å¯†åº¦",
               data_for_map,
               maptype="china",
               is_roam=True,  # å…è®¸åœ°å›¾ç¼©æ”¾å’Œæ‹–åŠ¨
         )
         .set_global_opts(
               title_opts=opts.TitleOpts(title="ä¸­å›½å„çœæ•°æ®å¯†åº¦"),
               visualmap_opts=opts.VisualMapOpts(
                  min_=min(province_counts['count']),
                  max_=max(province_counts['count']),
               ),
         )
      )
      # ç”Ÿæˆ HTML
      html = map_chart.render_embed()
      # æ¸²æŸ“åœ°å›¾åˆ° Streamlit
      components.html(html, height=600)

      # åˆ›å»ºä¸‹è½½æŒ‰é’®
      st.write("")  # ç©ºè¡Œåˆ†éš”
      col1, col2 = st.columns([0.9, 0.1])  # å°†é¡µé¢åˆ†ä¸ºä¸¤åˆ—ï¼Œåœ°å›¾å  90%ï¼ŒæŒ‰é’®å  10%
      with col1:
         st.write("")  # å ä½ç¬¦
      with col2:
         # å°† province_counts è½¬æ¢ä¸º CSV æ–‡ä»¶
         csv = province_counts.to_csv(index=False).encode('utf-8')
         # æ·»åŠ ä¸‹è½½æŒ‰é’®ï¼Œä½¿ç”¨ç»å…¸å›¾æ ‡ ğŸ“¥
         st.download_button(
               label="ğŸ“¥",  # ä½¿ç”¨å›¾æ ‡ä½œä¸ºæŒ‰é’®
               data=csv,
               file_name="province_counts.csv",
               mime="text/csv",
               key="download_button",
         )